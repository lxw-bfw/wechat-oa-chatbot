# wechat-oa-chatbot

## ✨说明

搭建微信公众号基础聊天机器人服务，支持GPT系列、DeepSeek系列大模型，演示demo底座大模型采用`DeepSeek-v3`模型，支持配置，参考环境变量文件。

支持处理文本、语音和图片消息。

扩展外部工具功能：

- [ ] 联网查询实时信息
- [ ] 总结网页
- [ ] 天气出行助手

优化用户体验，适配微信被动回复消息5秒限制问题；

搭建access_token中控服务，优化微信access_token获取、过期、查询次数限制等系列问题；

...

## 🚀演示

### （demo）测试

扫描下方公众号二维码，关注后发送消息即可体验demo版

<img src="http://mmbiz.qpic.cn/mmbiz_jpg/hibaEe8ciaqzQicl0KPXxgaDXYZUEwWmpPVpCZNZ4ReQUIal9crxEketfyt3WT5b42ChhTWmpdnF0t5MIEoPmOeCw/0" alt="!text" style="zoom:50%;" />

### demo演示视频

点击下面视频封面，跳转到视频演示页面

[<img src="https://ik.imagekit.io/lxwgemmke/wechatmp/bd68e01b04cef8a24af2b211d857b1f.jpg?updatedAt=1748174501972" alt="演示视频" style="zoom:50%;" />](https://b23.tv/xPI6KL2)

### 我的AI信息、工具分享公众号【LW的AI信息屋】

关注下方公众号，可以体验更多功能，目前底座模型是`gpt4o`

![text](https://ik.imagekit.io/lxwgemmke/wechatmp/AI%E4%BF%A1%E6%81%AF%E5%B1%8B%E5%85%AC%E4%BC%97%E5%8F%B7.jpg?updatedAt=1748167335875)



## 💌不同消息类型处理

- [x] 文本消息处理和回复（文本-文本）
- [x] 图片消息处理和回复（图片-文本）
- [x] 语音消息处理和回复
  - [x] 语音-文本
  - [ ] 语音-语音

- [ ] 图片生成和回复图片（生成图片需求-符合需求的图片）



## 🐱‍💻被动回复消息的接口限制带来的问题

### 5秒内必须响应+三次重试机会

- 异步接口任务尤其是AI大模型的回复接口和语音处理任务等带来的耗时与之形成的冲突
- 充分利用多次重试机会来对耗时任务进行优化以提升用户体验，过程中带来的比较大的逻辑复杂度问题
- 多次请求可能带来的缓存竞态问题

### 回复内容的长度限制问题

- 缓存、分割和分步响应给用户

## 🎗被动回复消息接口的一些限制

#### 问题总结

1. **5秒超时限制**：微信服务器在向开发者服务器发送用户消息后，会等待最多5秒的响应。如果5秒内没有收到HTTP 200的响应，微信会认为此次请求失败。
2. **重试机制**：如果5秒超时，微信服务器会进行重试，总共尝试3次（总计约15秒）。如果3次都失败（即15秒内开发者服务器未能成功响应），微信将向用户显示“该公众号提供的服务出现故障，请稍后再试”的默认提示，那么本轮用户的提问，就无法得到应该有的回复
3. **消息内容长度限制**：
   - 文本消息 (text)：回复的文本内容，UTF-8编码，长度限制为**2048字节**（约682个汉字）。
   - 其他类型消息（图片、语音、视频、图文等）也有各自的大小和数量限制。

#### 策略分析

- **被动回复消息请求生命周期为5秒，用户一条消息的有效生命周期15秒**：
  - 构建合适的对象用于描述用户的当前消息和状态，并进行缓存
  - 提供用户提示机制，例如超时后优先回复用户：【正在深入思考中，请稍后回复任意文字尝试获取回复内容...】。
  - 启动对回复内容的异步缓存方案
    - 关联用户
    - 标记不同阶段的状态，实现判断当前阶段和给出不同处理策略
      - 给用户的回复策略
      - 等待和有效时间利用策略
      - 避免重复请求带来的多种任务保留语音处理、大模型接口调用的多次触发
    - 合适的缓存失效时间，避免过时的信息堆积，比如用户长时间未回来获取，则自动清除。
    - 缓存库：使用redis
    - 会引入更多复杂度，可能还会有缓存竞态问题
  - 设置大模型接口的最终超时处理（保留设置2分钟超时）
    - 避免当前论对话一直循环在“【正在深入思考中，请稍后回复任意文字尝试获取回复内容...】”导致卡死
    - 不论最终大模型接口是否能成功响应，用户都会在超时时间（比如2分钟）后获取到回复的结果，可能是正确的`大模型的答复内容`，也可能是当前回复的`错误原因提示`
- **超出微信官方对自动回复的消息内容长度限制**：
  - **分多条被动回复—基于队列的分段处理**
    - 将AI的长回复按2048字节（或略小，如2000字节，为序号和提示留余地）**分段**（或**切块**），并将这些**片段**存储在一个**队列**中
      - **首次回复**：**出队**第一个片段并发送，在末尾追加提示，例如“（非完整内容，请回复任意文字以获取剩余内容）”。
      - **后续处理：** 关联用户ID，**缓存**当前队列。重复上述**出队**和发送步骤，直到队列**清空**。

## ⚽大模型能力接入

-  支持OpenAI接口规范的任意大模型
- 多轮对话上下文记忆
- 语音和图片处理
- 工具调用

## 🎊其他

- [x] access_token中控服务
  - **唯一职责**：管理 access_token。
  - **主动刷新**：开启一个定时任务，在 access_token 过期前（比如提前10-30分钟）就主动去微信服务器获取新的 access_token，并将其存储起来（比如存到Redis、内存，或数据库）。
  - **被动刷新**：如果由于某种原因（网络问题、微信服务器抖动）主动刷新失败，或者wechat-api业务层调用，发现当前token已失效，中控服务器应该有能力在被请求时发现token无效并立即尝试刷新。
  - **存储**：安全地存储当前有效的 access_token 及其过期时间。
  - **并发锁**：**极其重要！** 当多个请求同时发现token需要刷新时，必须只有一个请求去执行刷新操作，其他请求等待结果。否则会多次调用微信获取token的接口，可能导致API调用超限或获取到不同的token引发混乱。
  - **提供接口**：具体的业务逻辑方不做任何涉及access_token相关的处理，唯一仅从access_token中控服务获取有效的access_token
- [ ] 支持Docker部署

## 👏快速开始

### 安装依赖

```bash
npm i -g pnpm

pnpm install 
```

### 开发环境

```bash
pnpm dev
open http://localhost:7001/
```

### 生产环境

```bash
pnpm start
pnpm stop
```

